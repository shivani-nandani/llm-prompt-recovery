{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2230f10c-5997-4852-bacb-3de64c2bf01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51b2c9276a641af999d8df6f1b00964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggleâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "kagglehub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b121179d-4407-43d4-8899-6b967a37d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U torch immutabledict sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a161ac-22f4-4e81-9167-1bb6c29e6e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/home/akobawal/gemma_pytorch/gemma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edd6764e-2706-47c5-829e-6a31f0a2276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gemma_pytorch.gemma.config import GemmaConfig, get_config_for_7b\n",
    "from gemma_pytorch.gemma.model import GemmaForCausalLM\n",
    "import torch as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3cbf2ea-b207-4a17-ad56-d547bdaa8edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "VARIANT = \"7b\" \n",
    "MACHINE_TYPE = \"cuda\" if pt.cuda.is_available() else \"cpu\"\n",
    "device = pt.device(MACHINE_TYPE)\n",
    "weights_dir = '/home/akobawal/LLM_Prompt_Recovery/gemma-7b-model'\n",
    "\n",
    "model_config = get_config_for_7b()\n",
    "model_config.tokenizer = \"/scratch/akobawal/tokenizer.model\"\n",
    "model_config.quant = \"quant\" in VARIANT\n",
    "\n",
    "# dtype = model_config.get_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519c5671-c5e0-406a-8e59-f3dd6a384425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(MACHINE_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bc01e35-c6db-44ec-a8f1-5872b8de5e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.set_default_dtype(pt.bfloat16)\n",
    "model = GemmaForCausalLM(model_config)\n",
    "model.load_weights('/scratch/akobawal/gemma-7b.ckpt')\n",
    "model = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca562e72-0a2a-4230-844b-6ecf4df8176f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ForumTopicId</th>\n",
       "      <th>PostUserId</th>\n",
       "      <th>PostDate</th>\n",
       "      <th>ReplyToForumMessageId</th>\n",
       "      <th>Message</th>\n",
       "      <th>Medal</th>\n",
       "      <th>MedalAwardDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>667016</td>\n",
       "      <td>116038</td>\n",
       "      <td>2708132</td>\n",
       "      <td>11/06/2019 18:06:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Just realized that the true CEF is wrong fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>667014</td>\n",
       "      <td>113221</td>\n",
       "      <td>2358604</td>\n",
       "      <td>11/06/2019 18:05:48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Looks really helpful ... &lt;/p&gt;</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11/13/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>667013</td>\n",
       "      <td>116036</td>\n",
       "      <td>1788308</td>\n",
       "      <td>11/06/2019 18:05:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Might someone downloaded train images 180+ ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11/12/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>667012</td>\n",
       "      <td>116035</td>\n",
       "      <td>2532029</td>\n",
       "      <td>11/06/2019 18:05:28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Nice Article, Arjit!\\nJust a small point th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>667011</td>\n",
       "      <td>116032</td>\n",
       "      <td>413189</td>\n",
       "      <td>11/06/2019 18:02:30</td>\n",
       "      <td>666992.0</td>\n",
       "      <td>&lt;p&gt;Nope it was actually taking lot of space. S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  ForumTopicId  PostUserId             PostDate  \\\n",
       "0  667016        116038     2708132  11/06/2019 18:06:31   \n",
       "1  667014        113221     2358604  11/06/2019 18:05:48   \n",
       "2  667013        116036     1788308  11/06/2019 18:05:43   \n",
       "3  667012        116035     2532029  11/06/2019 18:05:28   \n",
       "4  667011        116032      413189  11/06/2019 18:02:30   \n",
       "\n",
       "   ReplyToForumMessageId                                            Message  \\\n",
       "0                    NaN  <p>Just realized that the true CEF is wrong fo...   \n",
       "1                    NaN                   <p>Looks really helpful ... </p>   \n",
       "2                    NaN  <p>Might someone downloaded train images 180+ ...   \n",
       "3                    NaN  <p>Nice Article, Arjit!\\nJust a small point th...   \n",
       "4               666992.0  <p>Nope it was actually taking lot of space. S...   \n",
       "\n",
       "   Medal MedalAwardDate  \n",
       "0    NaN            NaN  \n",
       "1    3.0     11/13/2019  \n",
       "2    2.0     11/12/2019  \n",
       "3    NaN            NaN  \n",
       "4    NaN            NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "forum_messsages_df = pd.read_csv('/home/akobawal/LLM_Prompt_Recovery/ForumMessages.csv')\n",
    "forum_messsages_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c89f2437-d949-4cc4-aa82-2f9a1d4d5f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_texts = forum_messsages_df['Message'][::-1]\n",
    "original_texts = original_texts[5*len(original_texts)//6 + 5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e94c13ce-6901-4f9e-8327-8fe3a97ca492",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_prompts = [\n",
    "    'Explain this to me like I\\'m five.',\n",
    "    'Convert this into a sea shanty.',\n",
    "    'Make this rhyme.',\n",
    "    'write in style of a Novel',\n",
    "    'write in style of a Short story',\n",
    "    'write in style of a Poetry',\n",
    "    'write in style of a Drama (play)',\n",
    "    'write in style of a Essay',\n",
    "    'write in style of a Biography',\n",
    "    'write in style of a Autobiography',\n",
    "    'write in style of a Memoir',\n",
    "    'write in style of a Satire',\n",
    "    'write in style of a Fable',\n",
    "    'write in style of a Allegory',\n",
    "    'write in style of a Parable',\n",
    "    'write in style of a Epic',\n",
    "    'write in style of a Lyric poetry',\n",
    "    'write in style of a Sonnet',\n",
    "    'write in style of a Haiku',\n",
    "    'write in style of a Ballad',\n",
    "    'write in style of a Villanelle',\n",
    "    'write in style of a Ode',\n",
    "    'write in style of a Elegy',\n",
    "    'write in style of a Free verse',\n",
    "    'write in style of a Prose poetry',\n",
    "    'write in style of a Flash fiction',\n",
    "    'write in style of a Science fiction',\n",
    "    'write in style of a Fantasy',\n",
    "    'write in style of a Mystery',\n",
    "    'write in style of a Thriller',\n",
    "    'write in style of a Romance',\n",
    "    'write in style of a Historical fiction',\n",
    "    'write in style of a Gothic fiction',\n",
    "    'write in style of a Haiku',\n",
    "    'write in style of a Light Poetry',\n",
    "    'write in style of a verse',\n",
    "    'write in style of a Elegy',\n",
    "    'write in style of a Sonnet',\n",
    "    'write in style of a Limerick',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ed28ba3-529c-4d92-a4b9-f65328465565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "USER_CHAT_TEMPLATE = \"<start_of_turn>user\\n{prompt}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "\n",
    "rewrite_data = []\n",
    "x = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a0754e-9a3f-4ef3-aa55-9a4eb1804838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "for original_text in original_texts:\n",
    "    rewrite_prompt = random.choice(rewrite_prompts)\n",
    "    prompt = f'{rewrite_prompt}\\n{original_text}'\n",
    "    if len(prompt)>8162: continue\n",
    "    rewritten_text = model.generate(\n",
    "        USER_CHAT_TEMPLATE.format(prompt=prompt),\n",
    "        device=device,\n",
    "        output_len=100,\n",
    "    )\n",
    "    rewrite_data.append({\n",
    "        'original_text': original_text,\n",
    "        'rewrite_prompt': rewrite_prompt,\n",
    "        'rewritten_text': rewritten_text,\n",
    "    })\n",
    "    x+=1\n",
    "    if x%100==0:\n",
    "        rewrite_data_df = pd.DataFrame(rewrite_data)\n",
    "        rewrite_data_df.to_csv('gen_data.csv', sep=',', mode='a', index=False, encoding='utf-8')\n",
    "        rewrite_data = []\n",
    "        if x%1000==0: print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a39d8586-f476-4641-8f9e-13944b588f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Looks really helpful ... </p>write in style of a Science fiction\n",
      "<p>its all of it </p>ï»¿\n",
      "<p>My best friend and a role model</p>ï»¿\n",
      "<p>\"Your a robot</p><em>and</em><p>You can't read!\"</p>\n",
      "<p>I'm going to start writing and making videos because you gave me the courage to do that</p>\n",
      "Your best friend and a role model\n",
      "<p>They are great to you</p>\n",
      "<p\n"
     ]
    }
   ],
   "source": [
    "print(rewrite_data[1]['original_text'] + rewrite_data[1]['rewrite_prompt'] + '\\n' + rewrite_data[1]['rewritten_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5969e96-411a-44a1-9ce6-62ffcaa6b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for original_text in original_texts:\n",
    "    rewrite_prompt = random.choice(rewrite_prompts)\n",
    "    prompt = f'{rewrite_prompt}\\n{original_text}'\n",
    "    rewritten_text = model.generate(\n",
    "        USER_CHAT_TEMPLATE.format(prompt=prompt),\n",
    "        device=device,\n",
    "        output_len=100,\n",
    "    )\n",
    "    rewrite_data.append({\n",
    "        'original_text': original_text,\n",
    "        'rewrite_prompt': rewrite_prompt,\n",
    "        'rewritten_text': rewritten_text,\n",
    "    })\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate execution time\n",
    "execution_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6124b463-dffc-4eaa-a94d-d5533c05098a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242.08665442466736\n"
     ]
    }
   ],
   "source": [
    "print(execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f2fb27-cf57-4f7a-910c-a36d61b752da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_env",
   "language": "python",
   "name": "llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
